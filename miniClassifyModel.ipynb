{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "In this prototype model I am looking to create a basic classification model based on a dataset containing 1600 reviews, half being a mixture of truthful and the other half being deceptive. The deceptive reviews are from amazons mechanical turk program, where participants are told to create a review based on an experience they had never had. My aim is that by creating an initial model based on human deception, I will be able to later adapt the model with further training and tweaking into finding the different type of langauge used by a machines produced fake review.\n",
    "\n",
    "The dataset being used was created by a mixture of data from two studies into computational linguistics; M. Ott, Y. Choi, C. Cardie, and J.T. Hancock. [2011] and M. Ott, C. Cardie, and J.T. Hancock. [2013]. Data that is truthful are real reviews for hotels in Chicago taken from the sites Expedia, Hotels.com, Orbitz, Priceline, TripAdvisor and Yelp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>hotel</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>negative</td>\n",
       "      <td>Web</td>\n",
       "      <td>This was the 2nd time that we have stayed at t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    deceptive  hotel  polarity source  \\\n",
       "802  truthful  hyatt  negative    Web   \n",
       "\n",
       "                                                  text  \n",
       "802  This was the 2nd time that we have stayed at t...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = '/tmp/tfhub'\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/thestianchris/FakeReviewDetect/main/deceptive-opinion.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(df.shape)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17861515887414380930\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5717884928\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6225987997596090485\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:08:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Methodology**\n",
    "\n",
    "Commonsense baseline for indication of a deceptive or truthful review comes at a level of 50% accuracy if taken at a random guess\n",
    "\n",
    "standardize the data, token and indexing\n",
    "\n",
    "Standardise the text data in order to get rid of any encoding issues that might give different weight to text data based on capitalization and punctuation differences.\n",
    "\n",
    "tokenize using word2vec\n",
    "\n",
    "using lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian Gauthier\\AppData\\Local\\Temp\\ipykernel_31668\\3362262640.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'].str.replace('[^\\w\\s]','') #Remove punctuation\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Standardise\n",
    "for columns in df.columns:\n",
    "    df['text'] = df['text'].str.lower()   #Covert the text to lower case\n",
    "    df['text'].str.replace('[^\\w\\s]','') #Remove punctuation\n",
    "    df['text'].str.strip() #Remove whitespace\n",
    "    df['text'].str.replace(\"\\n\", \" \") #Remove escape characters\n",
    "\n",
    "#Shuffle the dataset to stop the model from picking up pattern of deceptive then truthful\n",
    "df = shuffle(df)\n",
    "\n",
    "#Get the max token from training data to be used in model\n",
    "max_length = 0\n",
    "for row in df['text']:\n",
    "    if len(row.split(\" \")) > max_length:\n",
    "        max_length = len(row.split(\" \"))\n",
    "\n",
    "print(max_length)\n",
    "\n",
    "text_data = df['text'].values  #Get the data from the dataset to be used in model, we only are focused on the review and deceptive label\n",
    "labels = df['deceptive'].values\n",
    "\n",
    "#Split the data into test and train data with a 80/20 split, with 80% going to the train data\n",
    "test_data, train_data, test_label, train_label = train_test_split(text_data,labels, test_size = 0.8, random_state = 0)\n",
    "\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 500) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Load Pretrained Word2Vec\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load('Embed')\n",
    "embeddings = embed([\"A long sentence.\", \"single-word\", \"http://example.com\"])\n",
    "print(embeddings.shape, embeddings.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_word2vec_enc(reviews):\n",
    "    encoded_reviews = []\n",
    "    for review in reviews:\n",
    "        tokens = review.split(\" \")\n",
    "        word2vec_embedding = embed(tokens)\n",
    "        encoded_reviews.append(word2vec_embedding)\n",
    "    return encoded_reviews\n",
    "\n",
    "def get_padded_encoded_reviews(encoded_reviews):\n",
    "    #Pad all the reviews so that they have the same length for model \n",
    "    padded_reviews_encoding = []\n",
    "    for enc_review in encoded_reviews:\n",
    "        zero_padding_cnt = max_length - enc_review.shape[0]\n",
    "        pad = np.zeros((1, 500)) #Value of 500 used as we are making a vector size of 500 to increase word relation\n",
    "        for i in range(zero_padding_cnt):\n",
    "            enc_review = np.concatenate((pad, enc_review), axis=0)\n",
    "        padded_reviews_encoding.append(enc_review)\n",
    "    return padded_reviews_encoding\n",
    "\n",
    "def label_encode(label):\n",
    "    #One hot encode label\n",
    "    if label == 'truthful':\n",
    "        return [1,0]\n",
    "    else:\n",
    "        return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Encode the reviews\n",
    "'''\n",
    "padded_encoded__train_reviews = get_padded_encoded_reviews(get_word2vec_enc(train_data))\n",
    "padded_encoded__test_reviews = get_padded_encoded_reviews(get_word2vec_enc(test_data))\n",
    "#Encode the labels\n",
    "encoded_train_label = [label_encode(label) for label in train_label]\n",
    "encoded_test_label = [label_encode(label) for label in test_label]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "320\n",
      "(1280, 784, 500)\n",
      "(320, 2)\n"
     ]
    }
   ],
   "source": [
    "#Turn values into numpy arrays so can be used in model\n",
    "'''\n",
    "train_data = np.array(padded_encoded__train_reviews)\n",
    "train_label = np.array(encoded_train_label)\n",
    "\n",
    "test_data = np.array(padded_encoded__test_reviews)\n",
    "test_label = np.array(encoded_test_label)\n",
    "\n",
    "#Save locally\n",
    "np.save('train_data', train_data)\n",
    "np.save('train_label', train_label)\n",
    "np.save('test_data', test_data)\n",
    "np.save('test_label', test_label)\n",
    "\n",
    "'''\n",
    "#Load locally\n",
    "train_data = np.load('train_data.npy')\n",
    "train_label= np.load('train_label.npy')\n",
    "\n",
    "test_data = np.load('test_data.npy')\n",
    "test_label = np.load('test_label.npy')\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(test_label))\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "13/13 [==============================] - 8s 113ms/step - loss: 0.7586 - accuracy: 0.4867\n",
      "Epoch 2/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.7485 - accuracy: 0.5219\n",
      "Epoch 3/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.7409 - accuracy: 0.5586\n",
      "Epoch 4/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.7312 - accuracy: 0.5727\n",
      "Epoch 5/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.7195 - accuracy: 0.5953\n",
      "Epoch 6/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.7086 - accuracy: 0.6187\n",
      "Epoch 7/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6999 - accuracy: 0.6133\n",
      "Epoch 8/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6943 - accuracy: 0.6398\n",
      "Epoch 9/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6791 - accuracy: 0.6453\n",
      "Epoch 10/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.6808 - accuracy: 0.6523\n",
      "Epoch 11/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.6551 - accuracy: 0.6742\n",
      "Epoch 12/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.6551 - accuracy: 0.6648\n",
      "Epoch 13/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.6291 - accuracy: 0.6945\n",
      "Epoch 14/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.6221 - accuracy: 0.6883\n",
      "Epoch 15/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.6099 - accuracy: 0.7086\n",
      "Epoch 16/250\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.5964 - accuracy: 0.7203\n",
      "Epoch 17/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.5768 - accuracy: 0.7289\n",
      "Epoch 18/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.5404 - accuracy: 0.7625\n",
      "Epoch 19/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.5572 - accuracy: 0.7391\n",
      "Epoch 20/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.5667 - accuracy: 0.7344\n",
      "Epoch 21/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.5792 - accuracy: 0.7242\n",
      "Epoch 22/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.5642 - accuracy: 0.7320\n",
      "Epoch 23/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.5307 - accuracy: 0.7633\n",
      "Epoch 24/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4918 - accuracy: 0.7969\n",
      "Epoch 25/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4913 - accuracy: 0.7836\n",
      "Epoch 26/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.5000 - accuracy: 0.7852\n",
      "Epoch 27/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.4537 - accuracy: 0.8258\n",
      "Epoch 28/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4416 - accuracy: 0.8297\n",
      "Epoch 29/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4450 - accuracy: 0.8234\n",
      "Epoch 30/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4599 - accuracy: 0.8125\n",
      "Epoch 31/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4437 - accuracy: 0.8266\n",
      "Epoch 32/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4110 - accuracy: 0.8406\n",
      "Epoch 33/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.4480 - accuracy: 0.8156\n",
      "Epoch 34/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4655 - accuracy: 0.8055\n",
      "Epoch 35/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.4091 - accuracy: 0.8430\n",
      "Epoch 36/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3886 - accuracy: 0.8516\n",
      "Epoch 37/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.3869 - accuracy: 0.8547\n",
      "Epoch 38/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.3529 - accuracy: 0.8727\n",
      "Epoch 39/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.3772 - accuracy: 0.8508\n",
      "Epoch 40/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.3790 - accuracy: 0.8492\n",
      "Epoch 41/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4379 - accuracy: 0.8227\n",
      "Epoch 42/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.5244 - accuracy: 0.7688\n",
      "Epoch 43/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.5559 - accuracy: 0.7367\n",
      "Epoch 44/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.5027 - accuracy: 0.7828\n",
      "Epoch 45/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4392 - accuracy: 0.8164\n",
      "Epoch 46/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4402 - accuracy: 0.8203\n",
      "Epoch 47/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.3792 - accuracy: 0.8461\n",
      "Epoch 48/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.3490 - accuracy: 0.8695\n",
      "Epoch 49/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.3399 - accuracy: 0.8719\n",
      "Epoch 50/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.3209 - accuracy: 0.8852\n",
      "Epoch 51/250\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.3145 - accuracy: 0.8844\n",
      "Epoch 52/250\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.3248 - accuracy: 0.8938\n",
      "Epoch 53/250\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.3829 - accuracy: 0.8422\n",
      "Epoch 54/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.3077 - accuracy: 0.9016\n",
      "Epoch 55/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.2706 - accuracy: 0.9102\n",
      "Epoch 56/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.2629 - accuracy: 0.9055\n",
      "Epoch 57/250\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.2826 - accuracy: 0.9078\n",
      "Epoch 58/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.2511 - accuracy: 0.9117\n",
      "Epoch 59/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.2520 - accuracy: 0.9102\n",
      "Epoch 60/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2598 - accuracy: 0.9195\n",
      "Epoch 61/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3268 - accuracy: 0.8797\n",
      "Epoch 62/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 1.2838 - accuracy: 0.6320\n",
      "Epoch 63/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6556 - accuracy: 0.6383\n",
      "Epoch 64/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.6543 - accuracy: 0.6383\n",
      "Epoch 65/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.6235 - accuracy: 0.6812\n",
      "Epoch 66/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.5942 - accuracy: 0.7156\n",
      "Epoch 67/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.5678 - accuracy: 0.7305\n",
      "Epoch 68/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.5403 - accuracy: 0.7500\n",
      "Epoch 69/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.5200 - accuracy: 0.7609\n",
      "Epoch 70/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4789 - accuracy: 0.7906\n",
      "Epoch 71/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4449 - accuracy: 0.8125\n",
      "Epoch 72/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4173 - accuracy: 0.8375\n",
      "Epoch 73/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3888 - accuracy: 0.8562\n",
      "Epoch 74/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4061 - accuracy: 0.8313\n",
      "Epoch 75/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.3600 - accuracy: 0.8578\n",
      "Epoch 76/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.2953 - accuracy: 0.9039\n",
      "Epoch 77/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3099 - accuracy: 0.8820\n",
      "Epoch 78/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.2806 - accuracy: 0.9070\n",
      "Epoch 79/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.2476 - accuracy: 0.9141\n",
      "Epoch 80/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.2513 - accuracy: 0.9227\n",
      "Epoch 81/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4763 - accuracy: 0.7844\n",
      "Epoch 82/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4920 - accuracy: 0.7836\n",
      "Epoch 83/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.4250 - accuracy: 0.8211\n",
      "Epoch 84/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4016 - accuracy: 0.8492\n",
      "Epoch 85/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.3676 - accuracy: 0.8539\n",
      "Epoch 86/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.3111 - accuracy: 0.8773\n",
      "Epoch 87/250\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.2478 - accuracy: 0.9227\n",
      "Epoch 88/250\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.2282 - accuracy: 0.9344\n",
      "Epoch 89/250\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.2367 - accuracy: 0.9250\n",
      "Epoch 90/250\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.1839 - accuracy: 0.9516\n",
      "Epoch 91/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.1967 - accuracy: 0.9430\n",
      "Epoch 92/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.1842 - accuracy: 0.9438\n",
      "Epoch 93/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.1609 - accuracy: 0.9578\n",
      "Epoch 94/250\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.1549 - accuracy: 0.9523\n",
      "Epoch 95/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.1598 - accuracy: 0.9555\n",
      "Epoch 96/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.1674 - accuracy: 0.9469\n",
      "Epoch 97/250\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.1538 - accuracy: 0.9563\n",
      "Epoch 98/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.1167 - accuracy: 0.9672\n",
      "Epoch 99/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.1230 - accuracy: 0.9688\n",
      "Epoch 100/250\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.1010 - accuracy: 0.9781\n",
      "Epoch 101/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0929 - accuracy: 0.9812\n",
      "Epoch 102/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0955 - accuracy: 0.9773\n",
      "Epoch 103/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.1269 - accuracy: 0.9625\n",
      "Epoch 104/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.1239 - accuracy: 0.9688\n",
      "Epoch 105/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.1180 - accuracy: 0.9672\n",
      "Epoch 106/250\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.1235 - accuracy: 0.9648\n",
      "Epoch 107/250\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.0751 - accuracy: 0.9883\n",
      "Epoch 108/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0695 - accuracy: 0.9891\n",
      "Epoch 109/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0501 - accuracy: 0.9977\n",
      "Epoch 110/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0479 - accuracy: 0.9977\n",
      "Epoch 111/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0565 - accuracy: 0.9937\n",
      "Epoch 112/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0514 - accuracy: 0.9953\n",
      "Epoch 113/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0539 - accuracy: 0.9945\n",
      "Epoch 114/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0494 - accuracy: 0.9945\n",
      "Epoch 115/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0525 - accuracy: 0.9930\n",
      "Epoch 116/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.1107 - accuracy: 0.9695\n",
      "Epoch 117/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0880 - accuracy: 0.9773\n",
      "Epoch 118/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0597 - accuracy: 0.9891\n",
      "Epoch 119/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0683 - accuracy: 0.9844\n",
      "Epoch 120/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0945 - accuracy: 0.9789\n",
      "Epoch 121/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0748 - accuracy: 0.9805\n",
      "Epoch 122/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0563 - accuracy: 0.9922\n",
      "Epoch 123/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0783 - accuracy: 0.9852\n",
      "Epoch 124/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0647 - accuracy: 0.9867\n",
      "Epoch 125/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0565 - accuracy: 0.9922\n",
      "Epoch 126/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 127/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0364 - accuracy: 0.9992\n",
      "Epoch 128/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0364 - accuracy: 0.9984\n",
      "Epoch 129/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.0337 - accuracy: 0.9992\n",
      "Epoch 130/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 131/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 132/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 133/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0321 - accuracy: 0.9992\n",
      "Epoch 134/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 135/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 136/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 137/250\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 138/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0298 - accuracy: 0.9992\n",
      "Epoch 139/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 140/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.0295 - accuracy: 0.9992\n",
      "Epoch 141/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 142/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.1471 - accuracy: 0.9672\n",
      "Epoch 144/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.2059 - accuracy: 0.9336\n",
      "Epoch 145/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.0737 - accuracy: 0.9852\n",
      "Epoch 146/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.0830 - accuracy: 0.9766\n",
      "Epoch 147/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.0616 - accuracy: 0.9930\n",
      "Epoch 148/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0472 - accuracy: 0.9969\n",
      "Epoch 149/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0408 - accuracy: 0.9945\n",
      "Epoch 150/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0403 - accuracy: 0.9953\n",
      "Epoch 151/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0391 - accuracy: 0.9969\n",
      "Epoch 152/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0381 - accuracy: 0.9977\n",
      "Epoch 153/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0313 - accuracy: 0.9992\n",
      "Epoch 154/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 155/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0308 - accuracy: 0.9992\n",
      "Epoch 156/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0292 - accuracy: 0.9984\n",
      "Epoch 157/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 158/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 159/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0264 - accuracy: 0.9992\n",
      "Epoch 160/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 161/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0256 - accuracy: 1.0000\n",
      "Epoch 162/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 163/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 164/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 165/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 166/250\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 167/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 168/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 169/250\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 170/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 171/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 172/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 173/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0254 - accuracy: 0.9992\n",
      "Epoch 174/250\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.0302 - accuracy: 0.9977\n",
      "Epoch 175/250\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.0331 - accuracy: 0.9945\n",
      "Epoch 176/250\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.0275 - accuracy: 0.9984\n",
      "Epoch 177/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0287 - accuracy: 0.9969\n",
      "Epoch 178/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0357 - accuracy: 0.9961\n",
      "Epoch 179/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0407 - accuracy: 0.9922\n",
      "Epoch 180/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0317 - accuracy: 0.9969\n",
      "Epoch 181/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0316 - accuracy: 0.9969\n",
      "Epoch 182/250\n",
      "13/13 [==============================] - 2s 115ms/step - loss: 0.0261 - accuracy: 0.9984\n",
      "Epoch 183/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 184/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0255 - accuracy: 0.9992\n",
      "Epoch 185/250\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 186/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 187/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 188/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 189/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 190/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 191/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 192/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0212 - accuracy: 0.9992\n",
      "Epoch 193/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0249 - accuracy: 0.9977\n",
      "Epoch 194/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0616 - accuracy: 0.9852\n",
      "Epoch 195/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0394 - accuracy: 0.9953\n",
      "Epoch 196/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0313 - accuracy: 0.9961\n",
      "Epoch 197/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 198/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 199/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 200/250\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 201/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 202/250\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 203/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 204/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 205/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 206/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 207/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 208/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 209/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 210/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 211/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 212/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0203 - accuracy: 0.9992\n",
      "Epoch 213/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0215 - accuracy: 0.9992\n",
      "Epoch 214/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0212 - accuracy: 0.9992\n",
      "Epoch 215/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 216/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 217/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 218/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 219/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 220/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 221/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 222/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 223/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 224/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 225/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 226/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 227/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 228/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 229/250\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.0202 - accuracy: 0.9984\n",
      "Epoch 230/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0193 - accuracy: 0.9992\n",
      "Epoch 231/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 232/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 233/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 234/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 235/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 236/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 237/250\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 238/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 239/250\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 240/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 241/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 242/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 243/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 244/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 245/250\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 246/250\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 247/250\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 248/250\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 249/250\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 250/250\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.0296 - accuracy: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100)               240400    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                3232      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244,194\n",
      "Trainable params: 244,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# LSTM model\n",
    "'''\n",
    "model = Sequential()\n",
    "model.build(input_shape=(train_data.shape))   \n",
    "model.add(layers.LSTM(100))                \n",
    "model.add(tf.keras.layers.Dropout(0.5))   \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu',\\\n",
    "                                kernel_regularizer=regularizers.l2(0.001),\\\n",
    "                                bias_regularizer=regularizers.l2(0.001),))\n",
    "model.add(tf.keras.layers.Dropout(0.5))      \n",
    "model.add(tf.keras.layers.Dense(16, activation='relu',\\\n",
    "                                kernel_regularizer=regularizers.l2(0.001),\\\n",
    "                                bias_regularizer=regularizers.l2(0.001),))          \n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "'''\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.build(input_shape=(train_data.shape))\n",
    "    model.add(layers.LSTM(100))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu',\n",
    "                                    kernel_regularizer=regularizers.l2(0.001),\n",
    "                                    bias_regularizer=regularizers.l2(0.001),))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu',\n",
    "                                    kernel_regularizer=regularizers.l2(0.001),\n",
    "                                    bias_regularizer=regularizers.l2(0.001),))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    train_label, \n",
    "    epochs = 250,\n",
    "    batch_size = 100\n",
    ") \n",
    "\n",
    "model.save('saved_model/my_model')\n",
    "model.summary()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys() # the data gathered during training\n",
    "\n",
    "def plot_acc():\n",
    "    plt.clf()\n",
    "    acc = history_dict['accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "    plt.title('Training acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_acc()\n",
    "early_stopping_epoch = np.argmax(history.history[\"accuracy\"])\n",
    "print(early_stopping_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100)               240400    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                3232      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244,194\n",
      "Trainable params: 244,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "9/9 [==============================] - 3s 124ms/step - loss: 0.1780 - accuracy: 0.9477\n",
      "Epoch 2/125\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 0.0572 - accuracy: 0.9836\n",
      "Epoch 3/125\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 0.0332 - accuracy: 0.9945\n",
      "Epoch 4/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 5/125\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 6/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 7/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 8/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 9/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 10/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 11/125\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 12/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 13/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 14/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 15/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 16/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 17/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 18/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 19/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 20/125\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 21/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 22/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 23/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 24/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 25/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 26/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 27/125\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.0144 - accuracy: 0.9992\n",
      "Epoch 28/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 29/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 30/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 31/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 32/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 33/125\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 34/125\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 0.0152 - accuracy: 0.9992\n",
      "Epoch 35/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 36/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0147 - accuracy: 0.9992\n",
      "Epoch 37/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 38/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0173 - accuracy: 0.9992\n",
      "Epoch 39/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0759 - accuracy: 0.9781\n",
      "Epoch 40/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0982 - accuracy: 0.9711\n",
      "Epoch 41/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0896 - accuracy: 0.9734\n",
      "Epoch 42/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0569 - accuracy: 0.9875\n",
      "Epoch 43/125\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 0.0431 - accuracy: 0.9914\n",
      "Epoch 44/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0344 - accuracy: 0.9945\n",
      "Epoch 45/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0277 - accuracy: 0.9953\n",
      "Epoch 46/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0196 - accuracy: 0.9992\n",
      "Epoch 47/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 48/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 49/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 50/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0226 - accuracy: 0.9984\n",
      "Epoch 51/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0175 - accuracy: 0.9992\n",
      "Epoch 52/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 53/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 54/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 55/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0162 - accuracy: 0.9992\n",
      "Epoch 56/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 57/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 58/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 59/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 60/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 61/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 62/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 63/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 64/125\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 65/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 66/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 67/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 68/125\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 69/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0150 - accuracy: 0.9992\n",
      "Epoch 70/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0141 - accuracy: 0.9992\n",
      "Epoch 71/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0139 - accuracy: 0.9992\n",
      "Epoch 72/125\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 73/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 74/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 75/125\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 76/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 77/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 78/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 79/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 80/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 81/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0134 - accuracy: 0.9992\n",
      "Epoch 82/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0145 - accuracy: 0.9992\n",
      "Epoch 83/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0146 - accuracy: 0.9992\n",
      "Epoch 84/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0147 - accuracy: 0.9992\n",
      "Epoch 85/125\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 0.0277 - accuracy: 0.9937\n",
      "Epoch 86/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0274 - accuracy: 0.9945\n",
      "Epoch 87/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0645 - accuracy: 0.9828\n",
      "Epoch 88/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.2183 - accuracy: 0.9352\n",
      "Epoch 89/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.1120 - accuracy: 0.9539\n",
      "Epoch 90/125\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 0.0663 - accuracy: 0.9820\n",
      "Epoch 91/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0329 - accuracy: 0.9953\n",
      "Epoch 92/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0231 - accuracy: 0.9992\n",
      "Epoch 93/125\n",
      "9/9 [==============================] - 1s 123ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 94/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 95/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0160 - accuracy: 0.9992\n",
      "Epoch 96/125\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 97/125\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 98/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 99/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 100/125\n",
      "9/9 [==============================] - 1s 123ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 101/125\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 102/125\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 103/125\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 104/125\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 105/125\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 106/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 107/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 108/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 109/125\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 110/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 111/125\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 112/125\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 113/125\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 114/125\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 115/125\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 116/125\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 117/125\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 118/125\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 119/125\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 120/125\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 121/125\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 122/125\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 123/125\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 124/125\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 125/125\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 0.0111 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2980631b550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(\n",
    "    train_data,                     # full training set\n",
    "    train_label,\n",
    "    epochs=early_stopping_epoch, # the epoch where overfitting starts\n",
    "    batch_size=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - loss: 1.2472 - accuracy: 0.7969 - 836ms/epoch - 84ms/step\n",
      "Test score: 1.2472294569015503\n",
      "Test accuracy: 0.796875\n"
     ]
    }
   ],
   "source": [
    "new_model.save('saved_model/my_model')\n",
    "final_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "score, acc = final_model.evaluate(test_data, test_label, verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9396d7d05074184ad1bdffa89c9baf4b70aedb99cfe5c454adbba107973e00ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
