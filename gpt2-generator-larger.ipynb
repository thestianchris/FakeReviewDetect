{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Import dependancies\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2') #Encoder text to tensor\n",
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian Gauthier\\AppData\\Local\\Temp\\ipykernel_28300\\1858399958.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  reviews['text'].str.replace('[^\\w\\s]','') #Remove punctuation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117686    lately we have been going to clearwater area a...\n",
      "312111    so nice they are so helpful. well make you sma...\n",
      "285079    upon entering it was packed for lunch on a sun...\n",
      "248579    food wasn't that good and it was very expensiv...\n",
      "177877    delicious. the best burros in tucson. i would ...\n",
      "                                ...                        \n",
      "261101    we had the appeitizer sampler which included a...\n",
      "268771    easily one of the best hotels in midwest and s...\n",
      "250221    today was my first ride at the studio and i co...\n",
      "316448    this is by far my favorite italian restaurant....\n",
      "379437    i got the piadina first. it's a wrap of sorts....\n",
      "Name: text, Length: 500000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Get Yelp dataset and standardise\n",
    "\n",
    "reviews = pd.read_csv('bigreviews.csv')\n",
    "reviews = shuffle(reviews)\n",
    "\n",
    "#Standardise and tokenize\n",
    "for column in reviews:\n",
    "    reviews['text'] = reviews['text'].str.lower()   #Covert the text to lower case\n",
    "    reviews['text'].str.replace('[^\\w\\s]','') #Remove punctuation\n",
    "    reviews['text'].str.strip() #Remove whitespace\n",
    "    reviews['text'].str.replace(\"\\n\", \" \") #Remove escape characters\n",
    "reviews = reviews['text']\n",
    "\n",
    "print(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian Gauthier\\AppData\\Local\\Temp\\ipykernel_28300\\4074793721.py:1: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  df1 = reviews[:50000]\n"
     ]
    }
   ],
   "source": [
    "df1 = reviews[:50000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method**\n",
    "From attempts to run the model as a whole, have had issues trying to run the large model and save weights due to the time to run epochs along with saving the dataframe, in attempt will train large model in chunks of 50k at a time and run the model using saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6504341 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#turn the entire reviews set into a long string to be segmented in next sequence\n",
    "single_string = ''\n",
    "for row in df1:\n",
    "  x = row\n",
    "  single_string += x \n",
    "string_tokenized = tokenizer.encode(single_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables to store the data\n",
    "examples = []\n",
    "block_size = 100\n",
    "BATCH_SIZE = 5 #reduce to 5\n",
    "BUFFER_SIZE = 1000\n",
    "# Split the string_tokenized list into blocks of size block_size\n",
    "# and store each block in the examples list\n",
    "for i in range(0, len(string_tokenized) - block_size + 1, block_size):\n",
    "  examples.append(string_tokenized[i:i + block_size])\n",
    "\n",
    "# Initialize empty lists for inputs and labels\n",
    "inputs, labels = [], [] \n",
    "\n",
    "# For each example in the examples list,\n",
    "# store input as the example without the last element\n",
    "# store the label as the example without the first element\n",
    "for ex in examples:\n",
    "  inputs.append(ex[:-1])\n",
    "  labels.append(ex[1:])\n",
    "\n",
    "# Create a dataset from the inputs and labels tensors\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "\n",
    "# Shuffle the dataset and batch it\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "# definining loss function\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# defining our metric which we want to observe\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "# compiling the model\n",
    "model.compile(loss=[loss], metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'tmp/weights.{epoch:02d}.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/Gelu/Pow' defined at (most recent call last):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 985, in launch_instance\n      app.start()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Christian Gauthier\\AppData\\Local\\Temp\\ipykernel_13608\\3057695578.py\", line 1, in <module>\n      history = model.fit(dataset, epochs=2,callbacks=[model_checkpoint_callback])\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1520, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 873, in run_call_with_unpacked_inputs\n      ignore_mismatched_sizes (`bool`, *optional*, defaults to `False`):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 906, in call\n      transformer_outputs = self.transformer(\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 873, in run_call_with_unpacked_inputs\n      ignore_mismatched_sizes (`bool`, *optional*, defaults to `False`):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 476, in call\n      for i, (block, layer_past) in enumerate(zip(self.h, past_key_values)):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 480, in call\n      outputs = block(\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 296, in call\n      m = self.mlp(m, training=training)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 218, in call\n      h = self.act(self.c_fc(x))\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations_tf.py\", line 105, in approximate_gelu_wrap\n      return tf.keras.activations.gelu(x, approximate=True)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\activations.py\", line 359, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/Gelu/Pow'\nfailed to allocate memory\n\t [[{{node tfgpt2lm_head_model_1/transformer/h_._10/mlp/Gelu/Pow}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_57246]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback])\n",
      "File \u001b[1;32mc:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/Gelu/Pow' defined at (most recent call last):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 985, in launch_instance\n      app.start()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Christian Gauthier\\AppData\\Local\\Temp\\ipykernel_13608\\3057695578.py\", line 1, in <module>\n      history = model.fit(dataset, epochs=2,callbacks=[model_checkpoint_callback])\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1520, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 873, in run_call_with_unpacked_inputs\n      ignore_mismatched_sizes (`bool`, *optional*, defaults to `False`):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 906, in call\n      transformer_outputs = self.transformer(\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 873, in run_call_with_unpacked_inputs\n      ignore_mismatched_sizes (`bool`, *optional*, defaults to `False`):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 476, in call\n      for i, (block, layer_past) in enumerate(zip(self.h, past_key_values)):\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 480, in call\n      outputs = block(\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 296, in call\n      m = self.mlp(m, training=training)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\", line 218, in call\n      h = self.act(self.c_fc(x))\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations_tf.py\", line 105, in approximate_gelu_wrap\n      return tf.keras.activations.gelu(x, approximate=True)\n    File \"c:\\Users\\Christian Gauthier\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\activations.py\", line 359, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tfgpt2lm_head_model_1/transformer/h_._10/mlp/Gelu/Pow'\nfailed to allocate memory\n\t [[{{node tfgpt2lm_head_model_1/transformer/h_._10/mlp/Gelu/Pow}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_57246]"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=2,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload model with saved weights**\n",
    "\n",
    "Create custom callback to save best epoch based on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('tmp\\weights.25.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 124439808 \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,439,808\n",
      "Trainable params: 124,439,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13008/13008 [==============================] - 2180s 167ms/step - loss: 4.6273 - accuracy: 0.2622\n",
      "Epoch 2/10\n",
      "13008/13008 [==============================] - 2091s 161ms/step - loss: 4.5439 - accuracy: 0.2722\n",
      "Epoch 3/10\n",
      "13008/13008 [==============================] - 2069s 159ms/step - loss: 4.4954 - accuracy: 0.2790\n",
      "Epoch 4/10\n",
      "13008/13008 [==============================] - 2072s 159ms/step - loss: 4.4696 - accuracy: 0.2837\n",
      "Epoch 5/10\n",
      "13008/13008 [==============================] - 2069s 159ms/step - loss: 4.4609 - accuracy: 0.2868\n",
      "Epoch 6/10\n",
      "13008/13008 [==============================] - 2107s 162ms/step - loss: 4.4285 - accuracy: 0.2909\n",
      "Epoch 7/10\n",
      "13008/13008 [==============================] - 2122s 163ms/step - loss: 4.3997 - accuracy: 0.2945\n",
      "Epoch 8/10\n",
      "13008/13008 [==============================] - 2078s 160ms/step - loss: 4.3860 - accuracy: 0.2969\n",
      "Epoch 9/10\n",
      "13008/13008 [==============================] - 2071s 159ms/step - loss: 4.3707 - accuracy: 0.2981\n",
      "Epoch 10/10\n",
      "13008/13008 [==============================] - 2072s 159ms/step - loss: 4.3357 - accuracy: 0.3004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ca3f320a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=10,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i found the staff to be very friendly and helpful.  \n",
      "\n",
      "i was in and out in less than an hour. they were able to get me in right away. i will definitely use them again.i have been here twice and both times were excellent. the food is delicious and the service is top-notch. if you're looking for a quick bite to eat, this is the place for you.this place is awesome! i came here with a group of friends and we nothing nothing like like nothing extra like such like extra nothing spot like, like spot nothing special nothing friendly nothing such nothing, extra extra spot friendly like other nothing while like friendly, nothing. nothing t like. like special like t nothing house extra such such\n"
     ]
    }
   ],
   "source": [
    "text = \"i found the\"\n",
    "# encoding the input text\n",
    "input_ids = tokenizer.encode(text, return_tensors='tf')\n",
    "# getting out output\n",
    "output = model.generate(\n",
    "  input_ids,\n",
    "  max_length = 150,\n",
    "  num_beams = 5,\n",
    "  temperature = 0.75,\n",
    "  no_repeat_ngram_size=2,\n",
    "  num_return_sequences=5\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9396d7d05074184ad1bdffa89c9baf4b70aedb99cfe5c454adbba107973e00ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
