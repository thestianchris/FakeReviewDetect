{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras module for building LSTM \n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# set seeds for reproducability\n",
    "from numpy.random import seed\n",
    "seed(54)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "True\n",
      "WARNING:tensorflow:From C:\\Users\\Christian Gauthier\\AppData\\Local\\Temp\\ipykernel_7484\\318039188.py:6: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Check if TensorFlow is using a GPU\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n",
      "92257    one star too many -- while are sever\\r\\nlori l...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "all_reviews = []\n",
    "\n",
    "reviews = pd.read_csv('reviews.csv')\n",
    "reviews = shuffle(reviews)\n",
    "\n",
    "#Standardise and tokenize\n",
    "for column in reviews:\n",
    "    reviews['text'] = reviews['text'].str.lower()   #Covert the text to lower case\n",
    "    reviews['text'].str.replace('[^\\w\\s]','') #Remove punctuation\n",
    "    reviews['text'].str.strip() #Remove whitespace\n",
    "    reviews['text'].str.replace(\"\\n\", \" \") #Remove escape characters\n",
    "reviews = reviews['text']\n",
    "\n",
    "#Use only a slice of the data\n",
    "reviews = reviews[:1100]\n",
    "print(len(reviews))\n",
    "print(reviews.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27, 160], [27, 160, 374], [27, 160, 374, 3275], [27, 160, 374, 3275, 212], [27, 160, 374, 3275, 212, 4], [27, 160, 374, 3275, 212, 4, 223], [27, 160, 374, 3275, 212, 4, 223, 52], [27, 160, 374, 3275, 212, 4, 223, 52, 104], [27, 160, 374, 3275, 212, 4, 223, 52, 104, 1056], [27, 160, 374, 3275, 212, 4, 223, 52, 104, 1056, 15]]\n"
     ]
    }
   ],
   "source": [
    "def get_sequence_of_tokens(reviews):\n",
    "  # Initialize the tokenizer\n",
    "  tokenizer = Tokenizer()\n",
    "\n",
    "  # Fit the tokenizer on the texts\n",
    "  tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "  # Get the total number of words\n",
    "  num_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "  # Convert the texts to sequences of tokens\n",
    "  sequences = []\n",
    "  for line in reviews:\n",
    "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "      for i in range(1, len(token_list)):\n",
    "          ngram_sequence = token_list[:i+1]\n",
    "          sequences.append(ngram_sequence)\n",
    "  return sequences, num_words\n",
    "\n",
    "# Get the input sequences and the total number of words\n",
    "sequences, num_words = get_sequence_of_tokens(reviews)\n",
    "\n",
    "# Print the first 10 input sequences\n",
    "print(sequences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pad_sequences(sequences):\n",
    "    # Find the maximum length of all sequences\n",
    "    max_sequence_len = max([len(x) for x in sequences])\n",
    "\n",
    "    # Pad all sequences to the maximum length\n",
    "    sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "    # Split the sequences into predictors and label\n",
    "    predictors, label = sequences[:,:-1],sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=num_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "\n",
    "predictors, label, max_sequence_len = gen_pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 817, 10)           88760     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               44400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8876)              896476    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,029,636\n",
      "Trainable params: 1,029,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, num_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(num_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(num_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, num_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3830/3830 [==============================] - 138s 35ms/step - loss: 6.6425\n",
      "Epoch 2/50\n",
      "3830/3830 [==============================] - 137s 36ms/step - loss: 6.2224\n",
      "Epoch 3/50\n",
      "3830/3830 [==============================] - 137s 36ms/step - loss: 5.9169\n",
      "Epoch 4/50\n",
      "3830/3830 [==============================] - 136s 36ms/step - loss: 5.6723\n",
      "Epoch 5/50\n",
      "3830/3830 [==============================] - 131s 34ms/step - loss: 5.4670\n",
      "Epoch 6/50\n",
      "3830/3830 [==============================] - 128s 33ms/step - loss: 5.2918\n",
      "Epoch 7/50\n",
      "3830/3830 [==============================] - 132s 35ms/step - loss: 5.1407\n",
      "Epoch 8/50\n",
      "3289/3830 [========================>.....] - ETA: 17s - loss: 4.9848"
     ]
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=50,batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    tokenizer = Tokenizer()\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "\n",
    "    # Use the `argmax()` method to get the index of the highest predicted probability\n",
    "    predicted_index = np.argmax(predicted)\n",
    "\n",
    "    output_word = \"\"\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            output_word = word\n",
    "            break\n",
    "    return seed_text + \" \" + output_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For what it is a\n",
      "For what it is a little casual delivery to find a great experience and the waitress was very friendly and the service was very friendly and the staff was friendly and the staff is very\n"
     ]
    }
   ],
   "source": [
    "review = (generate_text(\"For what it is\", 1, model, max_sequence_len))\n",
    "print (review)\n",
    "for i in range (30):\n",
    "    review = (generate_text(review, i, model, max_sequence_len))\n",
    "\n",
    "print(review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9396d7d05074184ad1bdffa89c9baf4b70aedb99cfe5c454adbba107973e00ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
